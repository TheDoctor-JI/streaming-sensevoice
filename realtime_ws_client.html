<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>WebSocket Audio Transcription</title>
    <style>
      body {
        user-select: none;
      }
      #transcriptionResult {
        white-space: pre-wrap;
        background-color: #f5f5f5;
        border: 1px solid #ddd;
        border-radius: 5px;

        font-family: monospace;
        margin-bottom: 84px;

        min-height: 40px;
      }
      #recordButton {
        border-radius: 10px;
        border: none;
        background-color: #e0e0e0;
        padding: 5px 10px;
      }
      #recordButton.recording {
        background-color: red;
        color: white;
      }
      div#transcriptionResult > div {
        display: grid;
        grid-template-columns: 30px 1fr;
        padding: 3px 5px;
        margin: 5px;
        gap: 3px;
      }

      .transTime {
        grid-column-start: 2;
        display: flex;
        grid-column-end: 3;
        grid-row-start: 2;
        grid-row-end: 2;
        padding: 0px 5px;
        color: #757575;
        font-size: 12px;
      }

      .transId {
        padding: 2px;
        border-radius: 10px;
        background-color: #fff;
        display: inline-flex;
        align-items: center;
        justify-content: center;
      }

      .transContent {
        padding: 3px;
        font-weight: 600;
        user-select: auto;
      }

      div#VADBox {
        position: fixed;
        width: 64px;
        height: 64px;
        border-radius: 100px;
        box-shadow: 2px 2px 6px #e0e0e0;
        display: flex;
        align-items: center;
        justify-content: center;
        top: 20px;
        right: 20px;
        background-color: white;
      }

      @media screen and (max-width: 600px) {
        div#VADBox {
          top: unset;
          bottom: 10px;
          right: calc(50% - 32px);
        }
      }

      .waveform-container {
        margin-top: 20px;
        padding: 15px;
        background: #f5f5f5;
        border-radius: 10px;
        border: 1px solid #ddd;
      }

      #waveformCanvas {
        width: 100%;
        height: 120px;
      }

      .audio-info {
        margin-top: 10px;
        font-family: monospace;
        font-size: 12px;
        color: #555;
      }

      .wordTimeline {
        grid-column: 2 / 3;
        display: flex;
        flex-wrap: wrap;
        gap: 6px;
        margin-top: 4px;
      }

      .wordTag {
        display: inline-flex;
        align-items: center;
        gap: 6px;
        padding: 3px 8px;
        border-radius: 12px;
        background: #ffffff;
        border: 1px solid #dcdcdc;
        font-size: 12px;
        line-height: 1.2;
        cursor: default;
      }

      .wordTag.final {
        border-color: #b3e5fc;
        background: #e1f5fe;
      }

      .wordTag.live {
        border-color: #ffe0b2;
        background: #fff3e0;
      }

      .wordTag:hover {
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }

      .wordTime {
        font-family: monospace;
        color: #616161;
        font-size: 11px;
      }
    </style>
  </head>
  <body>
    <div class="main-container">
      <div class="controls">
        <button id="recordButton">Start Recording</button>
        <div class="waveform-container">
          <canvas id="waveformCanvas" width="600" height="120"></canvas>
          <div class="audio-info" id="audioInfo">Idle</div>
        </div>
      </div>

      <hr />
      <p>Transcription result will be displayed below:</p>
      <div id="transcriptionResult"></div>
    </div>

    <div id="VADBox">
      <svg
        t="1729797715045"
        class="icon"
        viewBox="0 0 1024 1024"
        version="1.1"
        xmlns="http://www.w3.org/2000/svg"
        p-id="1395"
        width="32"
        height="32"
        id="MicrophoneWait"
      >
        <path
          d="M393.846154 301.948718m-301.948718 0a301.948718 301.948718 0 1 0 603.897436 0 301.948718 301.948718 0 1 0-603.897436 0Z"
          fill="#8CF6FB"
          p-id="1396"
        ></path>
        <path
          d="M932.102564 420.102564c0 216.615385-165.415385 397.784615-380.717949 418.789744l-65.641025 1.31282C263.876923 825.764103 91.897436 641.969231 91.897436 420.102564v-13.128205-6.564103C91.897436 382.030769 106.338462 367.589744 124.717949 367.589744S157.538462 382.030769 157.538462 400.410256V420.102564c0 195.610256 158.851282 354.461538 354.461538 354.461539s354.461538-158.851282 354.461538-354.461539v-13.128205-6.564103c0-18.379487 14.441026-32.820513 32.820513-32.820512s32.820513 14.441026 32.820513 32.820512V420.102564zM512 708.923077c-160.164103 0-288.820513-128.65641-288.820513-288.820513V288.820513C223.179487 128.65641 351.835897 0 512 0s288.820513 128.65641 288.820513 288.820513v131.282051c0 160.164103-128.65641 288.820513-288.820513 288.820513z m223.179487-420.102564c0-123.405128-99.774359-223.179487-223.179487-223.179487s-223.179487 99.774359-223.179487 223.179487v131.282051c0 123.405128 99.774359 223.179487 223.179487 223.179487s223.179487-99.774359 223.179487-223.179487V288.820513z"
          fill="#3C2DCB"
          p-id="1397"
        ></path>
        <path
          d="M551.384615 838.892308V958.358974h98.461539c18.379487 0 32.820513 14.441026 32.820513 32.820513S668.225641 1024 649.846154 1024h-275.692308c-18.379487 0-32.820513-14.441026-32.820513-32.820513s14.441026-32.820513 32.820513-32.820513H485.74359v-119.466666h65.641025z"
          fill="#D098FF"
          p-id="1398"
        ></path>
      </svg>
      <svg
        t="1729797571771"
        class="icon"
        viewBox="0 0 1024 1024"
        version="1.1"
        xmlns="http://www.w3.org/2000/svg"
        p-id="1395"
        width="32"
        height="32"
        id="MicrophoneListen"
      >
        <path
          d="M393.846154 301.948718m-301.948718 0a301.948718 301.948718 0 1 0 603.897436 0 301.948718 301.948718 0 1 0-603.897436 0Z"
          fill="#f9ba1c"
          p-id="1396"
        ></path>
        <path
          d="M932.102564 420.102564c0 216.615385-165.415385 397.784615-380.717949 418.789744l-65.641025 1.31282C263.876923 825.764103 91.897436 641.969231 91.897436 420.102564v-13.128205-6.564103C91.897436 382.030769 106.338462 367.589744 124.717949 367.589744S157.538462 382.030769 157.538462 400.410256V420.102564c0 195.610256 158.851282 354.461538 354.461538 354.461539s354.461538-158.851282 354.461538-354.461539v-13.128205-6.564103c0-18.379487 14.441026-32.820513 32.820513-32.820512s32.820513 14.441026 32.820513 32.820512V420.102564zM512 708.923077c-160.164103 0-288.820513-128.65641-288.820513-288.820513V288.820513C223.179487 128.65641 351.835897 0 512 0s288.820513 128.65641 288.820513 288.820513v131.282051c0 160.164103-128.65641 288.820513-288.820513 288.820513z m223.179487-420.102564c0-123.405128-99.774359-223.179487-223.179487-223.179487s-223.179487 99.774359-223.179487 223.179487v131.282051c0 123.405128 99.774359 223.179487 223.179487 223.179487s223.179487-99.774359 223.179487-223.179487V288.820513z"
          fill="#f95945"
          p-id="1397"
        ></path>
        <path
          d="M551.384615 838.892308V958.358974h98.461539c18.379487 0 32.820513 14.441026 32.820513 32.820513S668.225641 1024 649.846154 1024h-275.692308c-18.379487 0-32.820513-14.441026-32.820513-32.820513s14.441026-32.820513 32.820513-32.820513H485.74359v-119.466666h65.641025z"
          fill="#f94585"
          p-id="1398"
        ></path>
      </svg>
    </div>

    <script>
    var recordButton = document.getElementById("recordButton");
    var ws = null;
    var isRecording = false;

    var transcriptionList = [];
    var audioContext = null;
  var mediaStream = null;
  var audioWorkletNode = null;
  var resampleBuffer = new Float32Array(0);
  var waveformCanvas = document.getElementById("waveformCanvas");
  var waveformCtx = waveformCanvas.getContext("2d");
  var audioInfo = document.getElementById("audioInfo");
  var workletSourceNode = null;
  var silentGainNode = null;

    const TARGET_SAMPLE_RATE = 16000;
    const CHUNK_DURATION = 0.1; // seconds
    const CHUNK_SAMPLES = Math.floor(TARGET_SAMPLE_RATE * CHUNK_DURATION);
    const MAX_WAVEFORM_SAMPLES = 2048;

    recordButton.onclick = function () {
      if (!isRecording) {
        startRecording();
      } else {
        stopRecording();
      }
    };

    function formatSecondsLabel(seconds) {
      if (seconds === null || seconds === undefined || Number.isNaN(seconds)) {
        return "—";
      }
      return `${seconds.toFixed(2)}s`;
    }

    function formatTimeRange(relativeStart, relativeEnd) {
      if (
        relativeStart === null ||
        relativeStart === undefined ||
        Number.isNaN(relativeStart)
      ) {
        return "—";
      }

      const startLabel = formatSecondsLabel(relativeStart);
      if (relativeEnd === null || relativeEnd === undefined || Number.isNaN(relativeEnd)) {
        return `+${startLabel}`;
      }

      return `+${startLabel} → +${formatSecondsLabel(relativeEnd)}`;
    }

    function buildWordTimeline(transcription) {
      const wordEntries = transcription?.data?.word_timestamps;
      if (!Array.isArray(wordEntries) || wordEntries.length === 0) {
        return null;
      }

      const segmentStart = Number(
        transcription.segment_start_s ?? transcription.begin_at ?? 0
      );
      const isFinal = Boolean(transcription.is_final);

      const timeline = document.createElement("div");
      timeline.classList.add("wordTimeline");

      wordEntries.forEach((entry) => {
        const wordText = entry?.word ?? "";
        if (!wordText) {
          return;
        }

        const startMs = Number(
          entry.start_ms ?? (entry.start !== undefined ? entry.start * 1000 : NaN)
        );
        const endMs = Number(
          entry.end_ms ?? (entry.end !== undefined ? entry.end * 1000 : NaN)
        );

        const relStart = Number.isFinite(startMs) ? startMs / 1000 : null;
        const relEnd = Number.isFinite(endMs) ? endMs / 1000 : null;

        const absStart = relStart !== null ? segmentStart + relStart : null;
        const absEnd = relEnd !== null ? segmentStart + relEnd : null;

        const tag = document.createElement("span");
        tag.classList.add("wordTag");
        tag.classList.add(isFinal ? "final" : "live");
        tag.dataset.relativeStart = relStart !== null ? relStart.toFixed(3) : "";
        tag.dataset.relativeEnd = relEnd !== null ? relEnd.toFixed(3) : "";
        tag.dataset.absoluteStart = absStart !== null ? absStart.toFixed(3) : "";
        tag.dataset.absoluteEnd = absEnd !== null ? absEnd.toFixed(3) : "";

        const titleParts = [`Word: ${wordText}`];
        if (relStart !== null) {
          titleParts.push(`Segment +${formatSecondsLabel(relStart)}`);
        }
        if (relEnd !== null) {
          titleParts.push(`→ +${formatSecondsLabel(relEnd)}`);
        }
        if (absStart !== null) {
          titleParts.push(`Abs ${formatSecondsLabel(absStart)}`);
        }
        if (absEnd !== null) {
          titleParts.push(`→ ${formatSecondsLabel(absEnd)}`);
        }
        tag.title = titleParts.join(" | ");

        const wordSpan = document.createElement("span");
        wordSpan.textContent = wordText;

        const timeSpan = document.createElement("span");
        timeSpan.classList.add("wordTime");
        timeSpan.textContent = formatTimeRange(relStart, relEnd);

        tag.appendChild(wordSpan);
        tag.appendChild(timeSpan);

        tag.addEventListener("click", () => {
          const parts = [`${wordText}`];
          if (relStart !== null) {
            parts.push(`segment +${formatSecondsLabel(relStart)}`);
          }
          if (relEnd !== null) {
            parts.push(`→ +${formatSecondsLabel(relEnd)}`);
          }
          if (absStart !== null) {
            parts.push(`abs ${formatSecondsLabel(absStart)}`);
          }
          if (absEnd !== null) {
            parts.push(`→ ${formatSecondsLabel(absEnd)}`);
          }
          const detail = parts.join(" | ");
          if (audioInfo) {
            audioInfo.textContent = `Word detail: ${detail}`;
          }
          if (typeof window !== "undefined" && window.console) {
            window.console.debug("[WordTimestamp]", {
              word: wordText,
              relStart,
              relEnd,
              absStart,
              absEnd,
            });
          }
        });

        timeline.appendChild(tag);
      });

      if (!timeline.childElementCount) {
        return null;
      }

      return timeline;
    }

    function renderTranscrionResult(transcriptionList) {
      const fragment = document.createDocumentFragment();
      transcriptionList.forEach((transcription) => {
        const root = document.createElement("div");
        if (transcription.is_final) {
          const idEle = document.createElement("div");
          idEle.appendChild(document.createTextNode(transcription.id));
          idEle.classList.add("transId");
          root.appendChild(idEle);

          const transContentEle = document.createElement("div");
          transContentEle.appendChild(
            document.createTextNode(transcription.data.raw_text)
          );
          transContentEle.classList.add("transContent");
          root.appendChild(transContentEle);

          const timeEle = document.createElement("div");
          timeEle.appendChild(
            document.createTextNode(
              `${transcription.begin_at} ~ ${transcription.end_at}`
            )
          );
          timeEle.classList.add("transTime");
          root.appendChild(timeEle);

          const wordTimeline = buildWordTimeline(transcription);
          if (wordTimeline) {
            root.appendChild(wordTimeline);
          }
        } else {
          const idEle = document.createElement("div");
          idEle.appendChild(document.createTextNode(transcription.id));
          idEle.classList.add("transId");
          root.appendChild(idEle);

          const transContentEle = document.createElement("div");
          transContentEle.appendChild(
            document.createTextNode(transcription.data.raw_text)
          );
          transContentEle.classList.add("transContent");
          root.appendChild(transContentEle);

          const timeEle = document.createElement("div");
          timeEle.appendChild(
            document.createTextNode(`${transcription.begin_at} ~ Now`)
          );
          timeEle.classList.add("transTime");
          root.appendChild(timeEle);

          root.classList.add("isActive");

          const wordTimeline = buildWordTimeline(transcription);
          if (wordTimeline) {
            root.appendChild(wordTimeline);
          }
        }
        fragment.appendChild(root);
      });
      document.getElementById("transcriptionResult").innerHTML = "";
      document.getElementById("transcriptionResult").appendChild(fragment);
    }

    function renderVADEvent(is_active) {
      document.getElementById("MicrophoneWait").style.display = is_active
        ? "none"
        : "block";
      document.getElementById("MicrophoneListen").style.display = is_active
        ? "block"
        : "none";
    }
    renderVADEvent(false);

    function startRecording() {
      console.log("Start Recording");
      transcriptionList = [];
      document.getElementById("transcriptionResult").innerHTML = "";

      // Construct the query parameters
      var queryParams = [];
      var queryString =
        queryParams.length > 0 ? `?${queryParams.join("&")}` : "";

      ws = new WebSocket(
        `ws://${window.location.host}/api/realtime/ws${queryString}`
      );
      ws.binaryType = "arraybuffer";

      ws.onopen = function (event) {
        console.log("WebSocket connection established");
        initAudioProcessing();
      };

      ws.onmessage = function (evt) {
        console.log("Received message: " + evt.data);
        try {
          resJson = JSON.parse(evt.data);
          switch (resJson["type"]) {
            case "TranscriptionResponse":
              if (transcriptionList.length <= resJson["id"]) {
                transcriptionList.push(resJson);
              } else {
                transcriptionList[resJson["id"]] = resJson;
              }
              renderTranscrionResult(transcriptionList);
              break;
            case "VADEvent":
              renderVADEvent(resJson["is_active"]);
              break;
            default:
              transcriptionResult.textContent += "\n" + evt.data;
          }
        } catch (e) {
          console.error("Failed to parse response data", e);
          transcriptionResult.textContent += "\n" + evt.data;
        }
      };

      ws.onclose = function () {
        console.log("WebSocket connection closed");
        teardownAudioProcessing();
        if (isRecording) {
          recordButton.textContent = "Start Recording";
          recordButton.classList.remove("recording");
          isRecording = false;
        }
        ws = null;
      };

      ws.onerror = function (error) {
        console.error("WebSocket error: " + error);
        stopRecording();
      };

      recordButton.textContent = "Stop Recording";
      recordButton.classList.add("recording");
      isRecording = true;
    }

    function stopRecording() {
      console.log("Stop Recording");
      teardownAudioProcessing();
      if (ws) {
        ws.close();
      }
      recordButton.textContent = "Start Recording";
      recordButton.classList.remove("recording");
      isRecording = false;
    }

  async function initAudioProcessing() {
        const AudioCtx = window.AudioContext || window.webkitAudioContext;
        if (!AudioCtx) {
          alert("Web Audio API is not supported in this browser.");
          stopRecording();
          return;
        }

        try {
          audioContext = new AudioCtx({ sampleRate: TARGET_SAMPLE_RATE });
        } catch (err) {
          console.error("Failed to create audio context", err);
          alert("Unable to access audio context." + err.message);
          stopRecording();
          return;
        }

        try {
          await audioContext.audioWorklet.addModule("pcm-worklet-processor.js");
        } catch (err) {
          console.error("Failed to load audio worklet", err);
          alert("Unable to load audio worklet: " + err.message);
          stopRecording();
          return;
        }

        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          alert("Media devices API not supported in this browser.");
          stopRecording();
          return;
        }

        try {
          mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              channelCount: 1,
              sampleRate: TARGET_SAMPLE_RATE,
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
            },
          });
        } catch (err) {
          console.error("Microphone access denied", err);
          alert("Microphone access denied: " + err.message);
          stopRecording();
          return;
        }

        workletSourceNode = audioContext.createMediaStreamSource(mediaStream);
        audioWorkletNode = new AudioWorkletNode(audioContext, "pcm-worklet-processor", {
          numberOfInputs: 1,
          numberOfOutputs: 1,
        });

        audioWorkletNode.port.onmessage = function (event) {
          if (!event.data) {
            return;
          }

          const inputSampleRate = event.data.sampleRate || audioContext.sampleRate;
          let samples = event.data.samples;
          if (!samples) {
            return;
          }

          if (samples instanceof ArrayBuffer) {
            samples = new Float32Array(samples);
          }

          const resampled = resampleAudioBuffer(
            samples,
            inputSampleRate,
            TARGET_SAMPLE_RATE
          );
          resampleBuffer = appendFloat32(resampleBuffer, resampled);

          updateWaveform(resampled);
          audioInfo.textContent = `Streaming PCM | Mic SR: ${inputSampleRate.toFixed(
            0
          )} Hz | Buffer: ${resampleBuffer.length}`;

          while (resampleBuffer.length >= CHUNK_SAMPLES) {
            const chunk = resampleBuffer.slice(0, CHUNK_SAMPLES);
            resampleBuffer = resampleBuffer.slice(CHUNK_SAMPLES);
            sendPcmChunk(chunk);
          }
        };

        silentGainNode = audioContext.createGain();
        silentGainNode.gain.value = 0;

        workletSourceNode.connect(audioWorkletNode);
        audioWorkletNode.connect(silentGainNode);
        silentGainNode.connect(audioContext.destination);
      }

      function teardownAudioProcessing() {
        flushPendingAudio(true);
        resampleBuffer = new Float32Array(0);
        audioInfo.textContent = "Idle";

        if (audioWorkletNode) {
          audioWorkletNode.port.onmessage = null;
          audioWorkletNode.disconnect();
          audioWorkletNode = null;
        }

        if (silentGainNode) {
          silentGainNode.disconnect();
          silentGainNode = null;
        }

        if (workletSourceNode) {
          workletSourceNode.disconnect();
          workletSourceNode = null;
        }

        if (mediaStream) {
          mediaStream.getTracks().forEach((track) => track.stop());
          mediaStream = null;
        }

        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }

        if (waveformCtx) {
          waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          waveformCtx.beginPath();
          waveformCtx.moveTo(0, waveformCanvas.height / 2);
          waveformCtx.lineTo(waveformCanvas.width, waveformCanvas.height / 2);
          waveformCtx.strokeStyle = "#cccccc";
          waveformCtx.stroke();
        }
      }

      function resampleAudioBuffer(buffer, fromRate, toRate) {
        if (fromRate === toRate) {
          return buffer.slice();
        }

        const ratio = fromRate / toRate;
        const newLength = Math.round(buffer.length / ratio);
        const result = new Float32Array(newLength);

        for (let i = 0; i < newLength; i++) {
          const index = i * ratio;
          const lowerIndex = Math.floor(index);
          const upperIndex = Math.min(lowerIndex + 1, buffer.length - 1);
          const interp = index - lowerIndex;
          result[i] =
            buffer[lowerIndex] + interp * (buffer[upperIndex] - buffer[lowerIndex]);
        }

        return result;
      }

      function appendFloat32(existing, additional) {
        if (additional.length === 0) {
          return existing;
        }
        if (existing.length === 0) {
          return additional.slice();
        }

        const result = new Float32Array(existing.length + additional.length);
        result.set(existing, 0);
        result.set(additional, existing.length);
        return result;
      }

      function sendPcmChunk(floatChunk) {
        const int16Chunk = new Int16Array(floatChunk.length);
        for (let i = 0; i < floatChunk.length; i++) {
          const sample = Math.max(-1, Math.min(1, floatChunk[i]));
          int16Chunk[i] = sample < 0
            ? Math.round(sample * 0x8000)
            : Math.round(sample * 0x7fff);
        }

        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(int16Chunk.buffer);
        }
      }

      function flushPendingAudio(sendPartial = false) {
        if (!ws || ws.readyState !== WebSocket.OPEN) {
          return;
        }

        if (sendPartial && resampleBuffer.length > 0) {
          sendPcmChunk(resampleBuffer);
        }
      }

      function updateWaveform(samples) {
        if (!waveformCtx) return;

        if (!samples || samples.length === 0) {
          waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          waveformCtx.beginPath();
          waveformCtx.moveTo(0, waveformCanvas.height / 2);
          waveformCtx.lineTo(waveformCanvas.width, waveformCanvas.height / 2);
          waveformCtx.strokeStyle = "#cccccc";
          waveformCtx.stroke();
          return;
        }

        const displayCount = Math.min(samples.length, MAX_WAVEFORM_SAMPLES);
        const step = samples.length / displayCount;
        const normalized = new Float32Array(displayCount);

        for (let i = 0; i < displayCount; i++) {
          normalized[i] = samples[Math.floor(i * step)] || 0;
        }

        const { width, height } = waveformCanvas;
        waveformCtx.clearRect(0, 0, width, height);
        waveformCtx.beginPath();
        waveformCtx.moveTo(0, height / 2);
        waveformCtx.strokeStyle = "#007bff";
        waveformCtx.lineWidth = 1;

        for (let i = 0; i < normalized.length; i++) {
          const x = normalized.length > 1 ? (i / (normalized.length - 1)) * width : 0;
          const y = (0.5 - normalized[i] / 2) * height;
          waveformCtx.lineTo(x, y);
        }

        waveformCtx.stroke();
      }
      </script>
    </body>
  </html>
